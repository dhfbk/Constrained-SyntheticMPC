{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from analysis_function import *\n",
    "from structural_statistics import *\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "final_good_file = \"final_good_file\"\n",
    "final_filtering_good_file = \"final_filtering_good_file\"\n",
    "\n",
    "#open file using pickle\n",
    "with open(final_good_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "with open(final_filtering_good_file, 'rb') as file:\n",
    "    filtering = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847cc7b50998473",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progressist = [\n",
    "    \"ban of targeted killing\",\n",
    "    \"ban of the death penalty\",\n",
    "    \"recognition of the right to abortion\",\n",
    "    \"recognition of the right to euthanasia\",\n",
    "    \"recognition of Palestinian state\",\n",
    "    \"ban of mandatory military service\",\n",
    "    \"ban of nuclear weapons\",\n",
    "    \"mandatory sex education in schools\",\n",
    "    \"guarantee of online teaching\",\n",
    "    \"fight to climate change\",\n",
    "    \"incentives for renewable energy\",\n",
    "    \"ban of facial recognition technology\",\n",
    "    \"incentives for AI research\",\n",
    "    \"mandatory vaccination for children\",\n",
    "    \"ban of animal testing\",\n",
    "    \"incentives for organ donation\",\n",
    "    \"ban of racial profiling\",\n",
    "    \"incentives for immigration and asylum\",\n",
    "    \"universal healthcare\",\n",
    "    \"legalization of marijuana\",\n",
    "    \"legalization of same-sex marriage\",\n",
    "    \"legalization of surrogate motherhood\",\n",
    "    \"programme for the reduction of the gender pay gap\",\n",
    "    \"limitation to gun ownership\",\n",
    "    \"holocaust remembrance mandatory in schools\",\n",
    "    \"ban of zoos\",\n",
    "    \"protection of endangered species\",\n",
    "    \"organization of pride parades\",\n",
    "    \"allowance of tattoos\",\n",
    "    \"cohabitation of couples before marriage\",\n",
    "    \"ban of arranged marriages\",\n",
    "    \"US staying in NATO\",\n",
    "    \"Germany staying in EU\",\n",
    "    \"mandatory acceptance of mobile payments\",\n",
    "    \"lowering university tuition fees\",\n",
    "    \"mandatory cameras on police officers\",\n",
    "    \"freedom of blasphemy\",\n",
    "    \"legalization of adoption by same-sex couples\"]\n",
    "\n",
    "conservatist = [\n",
    "    \"allowance of targeted killing\",\n",
    "    \"allowance of the death penalty\",\n",
    "    \"ban of abortion\",\n",
    "    \"ban of euthanasia\",\n",
    "    \"non-recognition of Palestinian state\",\n",
    "    \"mandatory military service\",\n",
    "    \"support for nuclear weapons\",\n",
    "    \"optional sex education in schools\",\n",
    "    \"mandatory in-person teaching\",\n",
    "    \"opposition to regulations for action on climate change\",\n",
    "    \"incentives for energy from fossil fuels\",\n",
    "    \"incentives for facial recognition technology\",\n",
    "    \"opposition to AI research incentives\",\n",
    "    \"optional vaccination for children\",\n",
    "    \"allowance of animal testing\",\n",
    "    \"opposition to organ donation incentives\",\n",
    "    \"allowance of racial profiling\",\n",
    "    \"support to immigration contrast and stricter asylum rules\",\n",
    "    \"support to private healthcare\",\n",
    "    \"ban of marijuana\",\n",
    "    \"ban of same-sex marriage\",\n",
    "    \"ban of surrogate motherhood\",\n",
    "    \"increase of the gender pay gap in favor of men\",\n",
    "    \"right to unrestricted gun ownership\",\n",
    "    \"optional holocaust remembrance in schools\",\n",
    "    \"support for zoos\",\n",
    "    \"opposition to endangered species protection\",\n",
    "    \"ban of pride parades\",\n",
    "    \"ban of tattoos\",\n",
    "    \"mandatory marriage before cohabitation\",\n",
    "    \"right to arranged marriages\",\n",
    "    \"US leaving NATO\",\n",
    "    \"Germany leaving the EU\",\n",
    "    \"ban of mobile payments\",\n",
    "    \"increase in university tuition fees\",\n",
    "    \"freedom of police officers to refuse cameras\",\n",
    "    \"punishment for blasphemy\",\n",
    "    \"ban of adoption by same-sex couples\"]\n",
    "\n",
    "topics = progressist + conservatist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58494cb58a560dd5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "clusters_mess = [[]] * len(topics)\n",
    "clusters_conv = [[]] * len(topics)\n",
    "\n",
    "for d, t in zip(data, filtering):\n",
    "    item = json.loads(d)\n",
    "\n",
    "    conv = \"\"\n",
    "    mess = []\n",
    "\n",
    "    for turn in item[\"conversation\"]:\n",
    "        conv = conv +  turn[\"message\"] + \"\\n\"\n",
    "        mess.append(turn[\"message\"])\n",
    "\n",
    "    idx = topics.index(t[\"topic\"])\n",
    "\n",
    "    clusters_conv[idx] = clusters_conv[idx] + [conv]\n",
    "    clusters_mess[idx] = clusters_mess[idx] + [mess]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b4fc2ec547936",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4820a61fb11d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compare_conversations(conv_a, conv_b, model):\n",
    "    # Compute the cosine similarity between the two embeddings\n",
    "    similarities = util.pytorch_cos_sim(conv_a, conv_b)    #flatten the similarities matrix and return the top 5 values\n",
    "    # Flatten the tensor\n",
    "    flattened = similarities.flatten()\n",
    "\n",
    "    # Get the top 5 values\n",
    "    top5_values, _ = torch.topk(flattened, 5)  # Get the top 5 values\n",
    "    #average the top 5 values\n",
    "    top5_values = top5_values.mean()\n",
    "\n",
    "    return top5_values.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749de5a43089a77c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_cosine_similarity_from_list(embeddings, cluster_labels, top_k=5):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between clusters using a list of embeddings\n",
    "    and corresponding cluster labels.\n",
    "    \n",
    "    Args:\n",
    "        embeddings (list of torch.Tensor): List of individual embeddings (n x d).\n",
    "        cluster_labels (list of int): Cluster label for each embedding.\n",
    "        top_k (int): Number of top similarities to consider for each pair.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Average top_k similarities for each pair of clusters.\n",
    "    \"\"\"\n",
    "    # Convert embeddings and labels to tensors\n",
    "    embeddings = torch.stack(embeddings).to('cuda:0')\n",
    "    cluster_labels = torch.tensor(cluster_labels).to(embeddings.device)\n",
    "\n",
    "    # Normalize embeddings for cosine similarity\n",
    "    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # Compute the full cosine similarity matrix\n",
    "    similarity_matrix = torch.mm(embeddings, embeddings.T)\n",
    "\n",
    "    # Get unique cluster labels\n",
    "    unique_labels = cluster_labels.unique()\n",
    "    n_clusters = len(unique_labels)\n",
    "\n",
    "    # Prepare mask to exclude within-cluster comparisons\n",
    "    mask = torch.zeros_like(similarity_matrix, dtype=torch.bool)\n",
    "    for label in unique_labels:\n",
    "        cluster_indices = (cluster_labels == label).nonzero(as_tuple=True)[0]\n",
    "        mask[cluster_indices[:, None], cluster_indices] = True  # Mask diagonal and within-cluster\n",
    "\n",
    "    similarity_matrix.masked_fill_(mask, float('-inf'))  # Replace masked entries with -inf\n",
    "\n",
    "    # Compute top-k similarities for each pair of clusters\n",
    "    results = {}\n",
    "    for i, label_i in enumerate(unique_labels):\n",
    "        for j, label_j in enumerate(unique_labels[i + 1:], i + 1):\n",
    "            # Get indices for the two clusters\n",
    "            indices_i = (cluster_labels == label_i).nonzero(as_tuple=True)[0]\n",
    "            indices_j = (cluster_labels == label_j).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            # Extract sub-matrix for the cluster pair\n",
    "            sub_matrix = similarity_matrix[indices_i][:, indices_j]\n",
    "\n",
    "            # Get top-k similarities for each row\n",
    "            top_k_values, _ = torch.topk(sub_matrix, k=top_k, dim=1)\n",
    "\n",
    "            # Average the top-k values\n",
    "            avg_top_k_similarity = torch.mean(top_k_values).item()\n",
    "            results[(label_i.item(), label_j.item())] = avg_top_k_similarity\n",
    "            #print(f\"Avg Top-{top_k} Similarity between cluster {label_i.item()} and {label_j.item()}: {avg_top_k_similarity}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed750317a2fc1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = [[]] * len(topics)\n",
    "\n",
    "for idx, cluster in enumerate(clusters_mess):\n",
    "    print(idx)\n",
    "    for i in range(len(cluster)):\n",
    "        embeddings[idx] = embeddings[idx] + [model.encode(cluster[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60c0d55c020dbf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "rem_embeddings = [[]] * len(topics)\n",
    "cluster_labels = [[]] * len(topics)\n",
    "\n",
    "for idx, emb in enumerate(embeddings):\n",
    "    rem_emb = []\n",
    "    cl_labels = []\n",
    "    for i, e in enumerate(emb):\n",
    "        for ten in e:\n",
    "            rem_emb = rem_emb + [torch.Tensor(ten)]\n",
    "            cl_labels = cl_labels + [i]\n",
    "            \n",
    "    rem_embeddings[idx] = rem_emb\n",
    "    cluster_labels[idx] = cl_labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f669dd68060ca",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "count = 0\n",
    "for emb, lab in zip(rem_embeddings, cluster_labels):\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    results.append(compute_cosine_similarity_from_list(emb, lab, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91dd11f42cfe06a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_cluster = []\n",
    "for cluster in results:\n",
    "    res = []\n",
    "    for key in cluster:\n",
    "        res.append(cluster[key])\n",
    "\n",
    "    res_cluster.append(sum(res)/len(res))\n",
    "\n",
    "print(sum(res_cluster)/len(res_cluster))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
